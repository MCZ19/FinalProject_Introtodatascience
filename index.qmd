---
title: "Index"
author: "Anisha Kalra, Hannah Shepard-Moore, Gabriel Taylor, and Mitchell Zupko"
editor: visual
execute:
  warning: false
format:
  html:
    embed-resources: true
---

# Project Goals

DC residents can have vastly different outcomes along many dimensions for different demographics. Oftentimes, the neighborhood in which you live and the community to which you belong can lead to vastly different outcomes in terms of health, education, employment opportunities, etc. This project aims to explore whether demographic differences amongst student populations in DC public schools can be used to predict educational and/or employment outcomes.

# Literature Review

{literature review}

# Data Wrangling & Cleaning

```{r}
#packages used
library(tidyverse)
library(tidycensus)
library(sf)
library(sp)
library(tigris)
library(readxl)
library(dplyr)
library(readr)
library(tidyr)
library(dplyr)
library(recipes)
library(ggplot2)
library(janitor)
library(patchwork)
library(tidyclust)
library(tidymodels)
library(tidytext)
library(igraph)
library(ggraph)
library(stringr)
library(textrecipes)
library(stopwords)
library(glmnet) #glm package is incompatible with newer versions of R, according to error messages
library(MachineShop)
library(factoextra)
```

## Census Data

This data comes from the 2022 American Community Survey, and includes census tract-level data in the District of Columbia. The variables included are income, poverty status, SNAP participation, insurance coverage, Medicaid use, and occupants per room.

```{r}
#load variables
library(tidycensus)

demographics <- get_acs(geography= "tract",
                  state= "DC",
                  county = "District of Columbia",
                  geometry= TRUE,
                  variables= c("income" = "DP03_0062E", 
                               "poverty_universe" = "B17001_001",
                               "poverty_status" = "B17001_002",
                               "SNAP_universe" = "B22001_001",
                               "SNAP_status" = "B22001_002",
                               "insurance_universe" = "B27001_001",
                               "insurance_men" = "B27001_002",
                               "insurance_women" = "B27001_030"),
                  year= 2022,
                  progress= FALSE) |>
  select(-NAME,
         -moe) %>%
  pivot_wider(names_from = "variable",
              values_from = "estimate")

#Loading Population and medicaid separately, as they are at a different geo level
block_stats <- get_acs(geography= "block group",
                  state= "DC",
                  county = "District of Columbia",
                  geometry= TRUE,
                  variables= c("population" = "B01003_001",
                               "medicaid_19under" = "B27010_002",
                               "medicaid_19to34" = "B27010_018",
                               "medicaid_35to64" = "B27010_034",
                               "medicaid_65older" = "B27010_051"),
                  year= 2022,
                  progress= FALSE)

#st_write(demographics, "demographics.shp")
##need additional files (e.g. .shx, .proj, etc.)
demographics <- read_sf("demographics.shp")

#data cleaning

block_stats_clean <- block_stats %>%
  mutate(GEOID = substr(GEOID, 1, nchar(GEOID) - 1)) %>%
  mutate(estimate = as.numeric(estimate)) %>%
  select(-moe) %>% 
  st_drop_geometry() |>
  group_by(GEOID) %>% 
  pivot_wider(names_from = "variable",
              values_from = "estimate")|>
  mutate(medicaid = (medicaid_19under +
                       medicaid_19to34 +
                       medicaid_35to64 +
                       medicaid_65older)) |>
  select(-NAME) |> #Did not run properly dropping NAME in the earlier step
  group_by(GEOID) %>%
  summarise_all(sum) 

demographics <- merge(demographics, block_stats_clean, by = "GEOID", all.x = TRUE)

map_dbl(.x = demographics, .f = ~ sum(is.na(.x)))

#get rid of census tract with pop=0 or list
wider_demographics <- wider_demographics %>%
  filter(population != 0) %>% 
  filter(population != 1983) %>%
  mutate(poverty_status = as.numeric(poverty_status),
          SNAP_participation = as.numeric(SNAP_participation),
          insurance_coverage = as.numeric(insurance_coverage),
          medicaid = as.numeric(medicaid))
#convert totals to percentages
wider_demographics <- wider_demographics %>%
  mutate(poverty_perc = (poverty_status/population),
         SNAP_perc = (SNAP_participation/population),
         insurance_perc = (insurance_coverage/population),
         medicaid_perc = (medicaid/population))

```

## School Demographics, Test Scores, and Locations

This data comes from two sources, both of which provide data at the school level for elementary, middle, and high schools: District of Columbia Public Schools (proficiency) and DC Open Data (locations). The proficiency data includes both demographic data (racial and socioeconomic) and test data (English and math). The location data gives the latitude and longitude of each school. The dataset includes 73 public Elementary schools, 23 public Middle Schools, and 17 public High Schools in DC.

Note: The only racial data that was usable was the black population. All other racial groups had too many "n\<10" values, which were used for confidentiality reasons by the school system when the number of students in a racial group was less than 10. This is still a helpful measure of race-based school segregation.

```{r}
#read in the school data
proficiency <- read_xlsx("proficiency.xlsx")
#replacing "." with NAs
proficiency[proficiency == "."] <- NA
#missing data
map_dbl(.x = proficiency, .f = ~ sum(is.na(.x)))


#read in the location data
locations <- read_csv("DC_Public_Schools.csv")
locations <- locations %>%
  select(LONGITUDE, LATITUDE, SCHOOL_NAM, GRADES)
locations <- locations %>%
  rename(school_name = SCHOOL_NAM)

# match schools to locations
school_locations <- full_join(proficiency, locations,
                              by= "school_name")

#clean the school locations dataset
#take out NAs in school_locations
school_locations <- school_locations %>%
  filter(!is.na(LONGITUDE))
school_locations <- st_as_sf(school_locations,
                             coords = c("LONGITUDE", "LATITUDE")) %>%
  st_set_crs(value = 4269)
```

## Combined Data

```{r}
# match locations and demographics
st_crs(school_locations)
schools <- st_join(wider_demographics, school_locations,
                   join= st_contains)
```

## Data Cleaning

```{r}
# reducing NAs and changing names
schools <- schools %>%
  filter(!is.na(type)) %>%
  filter(!is.na(school_name)) %>%
  rename(income = DP03_0062)

#turning school type into a factor
schools <- schools %>%
  mutate(type = factor(type, levels = c("es", "ms", "hs"),
                       labels = c("Elementary School", "Middle School", "High School")))

# demographic percents
schools <- schools %>%
  mutate(black_pop = if_else(black_pop == "n < 10", 1, as.numeric(black_pop))) 
schools <- schools %>%
  mutate(poor_pop = if_else(poor_pop == "n < 10", 1, as.numeric(poor_pop))) 
schools <- schools %>%
  mutate(percent_black = black_pop/english_test)
schools <- schools %>%
  mutate(percent_poor = poor_pop/english_test)

#creation of outcome variables
# continuous: percent proficient in English
schools <- schools %>%
  mutate(percent_ela_proficient = ela_proficient/english_test)
# binary: (1) 50% or more proficient in English
schools <- schools %>%
  mutate(binary_ela_proficient = if_else(percent_ela_proficient >= .50, 1, 0))
# continuous: percent proficient in math
schools <- schools %>%
  mutate(percent_math_proficient = math_proficient/math_test)
# binary: (1) 50% or more proficient in math
schools <- schools %>%
  mutate(binary_math_proficient = if_else(percent_math_proficient >= .50, 1, 0))
```

# Exploratory Data Analysis

There are several variables of interest in our data for the exploratory data analysis, including the school location, the income and insurance use for the census tract, school test scores, and racial makeup of the school population.

### Where are there NAs?

First, we want to check if there are many missing values in the data. No more than 2 missing values exist for any one variable, and most have 0 or 1 missing value.

```{r}
map_dbl(.x = schools, .f = ~ sum(is.na(.x)))
```

### What does the distribution of the variables look like?

One can get a general sense of whether a variable is left-skewed, right-skewed, or more centralized by comparing the the relative difference in median and mean values. When the median is greater than the mean, the data may be left-skewed, and vice-versa for right-skewed data.

The percentage of school students who are considered poor is skewed to the left, meaning that a greater share of school populations have greater-than-average poverty (in this case, greater than 55%). ?????? for poverty among census tracts with a public school in the District of Columbia is slightly skewed to the right. \*\* How is this measured?\*\*

The racial makeup of DC public schools is skewed to the left as well, meaning that most schools have a greater-than-average percentage of students who identify as Black or African American (in this case, greater than 69%).

English-language proficiency scores across DC public schools is skewed to the right, meaning that in most schools, a less-than-average percentage of students received a proficient score (in this case, less than 32% proficient). Conversely, math proficiency scores are left-skewed, so in most schools, a greater-than-average percentage of students received a proficient score (in this case, more than 19% proficient). Unfortunately, in both cases, a very low percent of students receive proficient scores. For math, 75% of schools have a proficiency rate of 30% or less. For English, 75% of schools have a proficiency rate of 48% or less.

```{r}
summary(schools)
```

### What does the distribution of student populations look like?

```{r}
# Percent of students experiencing poverty
schools %>%
  ggplot(mapping= aes(x= percent_poor, fill=type)) +
  geom_histogram(bins= 10, 
                 show.legend = FALSE) +
  scale_x_continuous(breaks= c(0, .5, 1)) +
  facet_wrap(~type) +
  labs(title= paste("Across types of schools, populations tend to have greater",
                    "\nthan 50% poverty"),
       subtitle= paste("Elementary Schools are more segregated by poverty",
                       "level than Middle \nand High Schools"),
       x= "Percent of students who experience poverty",
       y= "Number of schools") +
  theme_minimal()
```

```{r}
# Percent of students who identify as Black or African American
schools %>%
  ggplot(mapping= aes(x= percent_black, fill=type)) +
  geom_histogram(bins= 10, 
                 show.legend = FALSE) +
  scale_x_continuous(breaks= c(0, .5, 1)) +
  facet_wrap(~type) +
  labs(title= paste("Across types of schools, most student populations are",
                    "\nmajority-Black and African American"),
       subtitle= paste("Many schools have nearly or 100% Black/African American",
                       "student populations"),
       x= "Percent of students who are Black/African American",
       y= "Number of schools") +
  theme_minimal()
```

### How do test scores vary by poverty

We tested both English and math scores, and they follow a similar trend, with some obvious outliers. As we explore further, we may need to pay attention the potential negative effects of income-based school segregation.

```{r}
#English Scores
schools %>%
  ggplot(mapping= aes(x= percent_poor,
                      y= percent_ela_proficient),
         color= "royalblue1") +
  geom_point(color= "grey50") +
  labs(title= paste("As the percent of students per school who experience",
                    "\npoverty rises, English proficiency rates fall"),
       subtitle= paste("There are several schools that are clear outliers or",
                       "stray from the \ngeneral trend"),
       x= "Percent of students who experience poverty",
       y= "Percent of students who received proficient English scores") +
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal()
```

### How do test scores vary by racial makeup?

This relationship is weaker than that of poverty and test scores, but generally test scores fall when schools have a higher Black/African American populations. As we explore further, we may need to pay attention the potential negative effects of racial school segregation.

```{r}
#English Scores
schools %>%
  ggplot(mapping= aes(x= percent_black,
                      y= percent_ela_proficient)) +
  geom_point(color= "grey50") +
  labs(title= paste("As the percent of students per school who identify as",
                    "Black \nor African American rises, English proficiency",
                    "rates fall"),
       subtitle= paste("This appears to be a weak relationship as many schools",
                       "stray from the \ngeneral trend"),
       x= "Percent of students who experience poverty",
       y= "Percent of students who received proficient English scores") +
  geom_smooth(method = "lm", se = FALSE, color= "red1") +
  theme_minimal()
```

# Geospatial Analysis

```{r, results='hide'}
states <- states()
```

```{r}
# English Scores across DC
schools %>%
  select(geometry, percent_ela_proficient) %>%
  ggplot() +
  geom_sf(data= states[states$STUSPS == "DC", ]) +
  geom_sf(data= schools,
          mapping= aes(fill= percent_ela_proficient)) +
  scale_fill_continuous(name = "English Proficiency Rate",
                        low= "firebrick",
                        high= "darkorange") +
  labs(title= paste("Schools with higher English proficiency rates",
                    "are \nconcentrated in Northeast DC"),
       subtitle= paste("DC Census Tracts with public schools show distribution",
                       "of higher and \nlower average school scores")) + 
  theme_minimal()
```

```{r}
# Distribution of poverty in schools across DC
schools %>%
  select(geometry, percent_poor) %>%
  ggplot() +
  geom_sf(data= states[states$STUSPS == "DC", ]) +
  geom_sf(data= schools,
          mapping= aes(fill= percent_poor)) +
  scale_fill_continuous(name = "Percent of students in poverty",
                        low= "royalblue",
                        high= "navy") +
  labs(title= paste("Schools with the most students in poverty",
                    "are concentrated \nin Southeast DC"),
       subtitle= paste("DC Census Tracts with public schools show distribution",
                       "of schools with \nhigher and lower poverty rates")) + 
  theme_minimal()
```

```{r}
# Racial makeup of schools across DC
schools %>%
  select(geometry, percent_black) %>%
  ggplot() +
  geom_sf(data= states[states$STUSPS == "DC", ]) +
  geom_sf(data= schools,
          mapping= aes(fill= percent_black)) +
  scale_fill_continuous(name = paste("Percent of students who are \nBlack or",
                                     "African American"),
                        low= "greenyellow",
                        high= "green4") +
  labs(title= paste("Most schools in East and Southeast DC are over",
                    "75% \nBlack or African American"),
       subtitle= paste("DC Census Tracts with public schools show distribution",
                       "of schools with higher \nand lower Black populations")) + 
  theme_minimal()
```

# Machine Learning Model

```{R}
# this is from Mitch and I's stretch exercise
schools_cond <- schools |>
  select(-NAME, 
         -geometry, 
         -GRADES, 
         -GEOID,
         -school_name,
         -type) |>
  st_drop_geometry() |>
  na.omit() %>%
  mutate_if(is.character, as.numeric)

educ_rec <- recipe(formula = ~., data = schools_cond) %>% 
  step_normalize %>% 
  step_pca() 

```

```{R}
educ_cv <- vfold_cv(schools_cond, v = 10)

kmeans_spec <- k_means(
  num_clusters = tune()) |>
  set_engine(
    "stats",
    nstart = 100
  )

kmeans_wflow <- workflow(
  preprocessor = educ_rec,
  spec = kmeans_spec) 

clust_num_grid <- grid_regular(
  num_clusters(),
  levels = 10
)

res <- tune_cluster(
  kmeans_wflow,
  resamples = educ_cv,
  grid = clust_num_grid,
  control = control_grid(save_pred = TRUE, 
                         extract = identity),
  metrics = cluster_metric_set(sse_within_total,
                               silhouette_avg))

```

```{R}
res %>%
  collect_metrics() %>%
  filter(.metric == "sse_within_total") %>%
  ggplot(aes(x = num_clusters, y = mean)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = 1:10) +
  labs(x = "Number of clusters",
       y = "mean WSS over 5 folds") +
  theme_minimal()

res %>%
  collect_metrics() %>%
  filter(.metric == "silhouette_avg") %>%
  ggplot(aes(x = num_clusters, 
             y = mean)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = 1:10) +
  labs(x = "Number of clusters",
       y = "mean WSS over 5 folds") +
  theme_minimal()

educ_numeric <- educ_rec %>% 
  prep() %>% 
  bake(new_data = schools_cond)

fviz_nbclust(educ_numeric, 
             FUN = kmeans, 
             method = "gap_stat")


#3b
kmeans_spec2 <- k_means(num_clusters = 1) %>% 
                          set_engine("stats", 
                                     nstart = 100)

kmeans_wflow2 <- workflow(preprocessor = educ_rec, 
                          spec = kmeans_spec2)

educ_kmeans_1 <- kmeans_wflow2 %>% 
  parsnip::fit(data = schools_cond)

#once again, using this fit codechunk returns the same error

#3c

cor(schools_cond)
#For Math Proficient 
#ela_proficient, math_4, #poverty_status

bind_cols(schools_cond,
          cluster = educ_kmeans_1 |>
            extract_cluster_assignment() |>
            pull(.cluster)) |>
  group_by(cluster) |>
  summarize(
    mean(ela_proficient),
    mean(math_4),
    mean(poverty_status) |>
      knitr::kable(digits = 3)
  )

```

# Findings
